{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "import tkinter as tk\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit space bar to capture\n",
    "def captureuser(name):\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    cv2.namedWindow(\"capture\")\n",
    "\n",
    "    img_counter = 0\n",
    "    \n",
    "    dirname = f'dataset/{name}'\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        cv2.imshow(\"capture\", frame)\n",
    "        \n",
    "        if img_counter == 5:\n",
    "            cv2.destroyWindow(\"capture\")\n",
    "            break\n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv2.waitKey(1)\n",
    "\n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k%256 == 32:\n",
    "            # SPACE pressed\n",
    "            path = f'dataset/{name}'\n",
    "            img_name = \"{}.jpg\".format(img_counter)\n",
    "            cv2.imwrite(os.path.join(path , img_name), frame)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "\n",
    "    cam.release()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captureuser('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(unique_id,name,bank, password, account_balance):\n",
    "    import csv\n",
    "    \n",
    "    with open(r'bank_details.csv','a', newline = '\\n') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([unique_id,name,bank, password, account_balance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    #summary:\n",
    "    \n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-i\", \"--dataset\", required=True,\n",
    "        help=\"path to input directory of faces + images\")\n",
    "    ap.add_argument(\"-e\", \"--embeddings\", required=True,\n",
    "        help=\"path to output serialized db of facial embeddings\")\n",
    "    ap.add_argument(\"-d\", \"--detector\", required=True,\n",
    "        help=\"path to OpenCV's deep learning face detector\")\n",
    "    ap.add_argument(\"-m\", \"--embedding-model\", required=True,\n",
    "        help=\"path to OpenCV's deep learning face embedding model\")\n",
    "    ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "        help=\"minimum probability to filter weak detections\")\n",
    "    \n",
    "    print(\"[INFO] loading face detector...\")\n",
    "\n",
    "    detector = cv2.dnn.readNetFromCaffe('face_detection_model/deploy.prototxt', 'face_detection_model/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "    embedder = cv2.dnn.readNetFromTorch('openface_nn4.small2.v1.t7')\n",
    "\n",
    "    print(\"[INFO] quantifying faces...\")\n",
    "    imagePaths = list(paths.list_images('dataset'))\n",
    "    knownEmbeddings = []\n",
    "    knownNames = []\n",
    "    total = 0\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
    "            len(imagePaths)))\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = imutils.resize(image, width=600)\n",
    "        (h, w) = image.shape[:2]\n",
    "        imageBlob = cv2.dnn.blobFromImage(\n",
    "            cv2.resize(image, (300, 300)), 1.0, (300, 300),\n",
    "            (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "        detector.setInput(imageBlob)\n",
    "        detections = detector.forward()\n",
    "\n",
    "        if len(detections) > 0:\n",
    "            \n",
    "            i = np.argmax(detections[0, 0, :, 2])\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "           \n",
    "            if confidence > 0.5:\n",
    "                \n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                face = image[startY:endY, startX:endX]\n",
    "                (fH, fW) = face.shape[:2]\n",
    "\n",
    "                if fW < 20 or fH < 20:\n",
    "                    continue\n",
    "\n",
    "                faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,\n",
    "                    (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "                embedder.setInput(faceBlob)\n",
    "                vec = embedder.forward()\n",
    "    \n",
    "                knownNames.append(name)\n",
    "                knownEmbeddings.append(vec.flatten())\n",
    "                total += 1\n",
    "    print(\"[INFO] serializing {} encodings...\".format(total))\n",
    "    data = {\"embeddings\": knownEmbeddings, \"names\": knownNames}\n",
    "    f = open('output/embeddings.pickle', \"wb\")\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    #summary    \n",
    "    \n",
    "    print(\"[INFO] loading face embeddings...\")\n",
    "    data = pickle.loads(open('output/embeddings.pickle', \"rb\").read())\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(data[\"names\"])\n",
    "    \n",
    "    print(\"[INFO] training model...\")\n",
    "    recognizer = SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "    recognizer.fit(data[\"embeddings\"], labels)\n",
    "    f = open('output/recognizer.pickle', \"wb\")\n",
    "    f.write(pickle.dumps(recognizer))\n",
    "    f.close()\n",
    "\n",
    "    f = open('output/le.pickle', \"wb\")\n",
    "    f.write(pickle.dumps(le))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
